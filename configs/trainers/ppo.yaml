--- # PPO
  include: default.yaml

  policy: glearn.policies:PPOPolicy

  # optimizer: adam
  # learning_rate: 2.0e-4
  # discount_factor: 0.95
  
  hidden_depth: 2
  hidden_size: 10
