--- # Actor Critic
  import: base

  env:
    name: glearn.envs.actor_critic_test:ActorCriticTestEnv
    args:
      max_undesired_steps: 10
      # mode: decaying
      # reward_multiple: 0
      # mode: sparse
  batch_size: 20

  policy:
    name: glearn.policies:NetworkPolicy
    args:
      network:
        optimizes: false
        layers:
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [16]
          - name: glearn.networks:CategoricalDistributionLayer

  trainer:
    name: glearn.trainers:ActorCriticTrainer
    args:
      critic:
        optimizer: adam
        learning_rate: 2.0e-1
        # optimizer: sgd
        # learning_rate: 2.0e-1
        layers:
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [16]
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [1]
              activation: null
      optimizer: adam
      learning_rate: 2.0e-1
      # optimizer: sgd
      # learning_rate: 2.0e-1
      gamma: 0.99
      # keep_prob: 0.8
      # epsilon: [1, 0.1, 2000]
      evaluate_interval: 100
      max_episode_time: 0.1
