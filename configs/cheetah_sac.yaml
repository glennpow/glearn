--- # Half Cheetah
  import: _base

  env: HalfCheetah-v2
  batch_size: 256

  policy:
    name: glearn.policies:NetworkPolicy
    args:
      network:
        layers:
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [256, 256]
          - name: glearn.networks:NormalDistributionLayer
        optimizer: adam
        learning_rate: 3.0e-4
        max_grad_norm: 5

  trainer:
    name: glearn.trainers:SoftActorCriticTrainer
    args:
      Q:
        layers:
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [256]
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [1]
              activation: null
        optimizer: adam
        learning_rate: 3.0e-4
        max_grad_norm: 5
      V:
        layers:
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [256]
          - name: glearn.networks:DenseLayer
            args:
              hidden_sizes: [1]
              activation: null
        optimizer: adam
        learning_rate: 3.0e-4
        max_grad_norm: 5
      gamma: 0.99
      tau: 5.0e-3
      ent_coef: 2.782559402207126e-05
      episodes: 1000
      # keep_prob: 0.8
      evaluate_interval: 10

  # sweeps:
  #   "trainer.args.learning_rate": [1.0e-2, 1.0e-3, 1.0e-4]
  #   "critic.learning_rate": [4.6e-1, 4.6e-2, 4.6e-4]
